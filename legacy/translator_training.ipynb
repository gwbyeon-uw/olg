{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd8c365-2b70-4d5d-a5bd-31f3c8a78b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trains the translator net\n",
    "import os\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Data import CodonTable\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch_optimizer as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir(\"/home/ubuntu/projects/olgdesign/\")\n",
    "\n",
    "from st import *\n",
    "from translator import *\n",
    "\n",
    "torch.set_num_threads(2)\n",
    "gpu_id = 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "device = torch.device(f'cuda:0') if gpu_id >= 0 else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7a7b5f-31a6-44ce-9c5c-1747f13127d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotides = ['A', 'T', 'G', 'C']\n",
    "amino_acids = list(\"ARNDCQEGHILKMFPSTWYV*\")\n",
    "\n",
    "nucs = np.array([0]*100)\n",
    "nucs[[65,84,71,67]] = [0,1,2,3] #ATGC\n",
    "\n",
    "aas = np.array([0]*100)\n",
    "aa_order = np.argsort(list(\"ARNDCQEGHILKMFPSTWYV\"))\n",
    "aas[[42,65,67,68,69,70,71,72,73,75,76,77,78,80,81,82,83,84,86,87,89]] = [20] + list(aa_order)\n",
    "\n",
    "len_pro = 500\n",
    "train_size = 10000\n",
    "test_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8f3189-3534-4865-a772-ecf92f64f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Generate random DNA\n",
    "def gen_random_dna(len_seqs, number_to_gen):\n",
    "    #returns list of uniform randomly generated nucleotide strings of a given length\n",
    "    return [''.join(random.choice(nucleotides) for i in range(len_seqs)) for j in range(0, number_to_gen)]\n",
    "all_dna  = gen_random_dna(len_pro * 3, train_size + test_size)\n",
    "random.shuffle(all_dna)\n",
    "\n",
    "#Generate protein sequences by translating DNA in all frames; forward strand\n",
    "all_prot_f1 = [ str(Seq(s).translate()) for s in all_dna ]\n",
    "all_prot_f2 = [ str(Seq(s[1:]).translate()) for s in all_dna ]\n",
    "all_prot_f3 = [ str(Seq(s[2:]).translate()) for s in all_dna ]\n",
    "\n",
    "#In reverse strand: reverse_complement, translate, then reverse\n",
    "all_prot_r1 = [ str(Seq(s).reverse_complement().translate())[::-1] for s in all_dna ]\n",
    "all_prot_r2 = [ str(Seq(s).reverse_complement()[2:].translate())[::-1] for s in all_dna ]\n",
    "all_prot_r3 = [ str(Seq(s).reverse_complement()[1:].translate())[::-1] for s in all_dna ]\n",
    "all_prot = [all_prot_f1, all_prot_f2, all_prot_f3, all_prot_r1, all_prot_r2, all_prot_r3]\n",
    "\n",
    "#DNA seq to tensor\n",
    "all_dna = np.array(all_dna)\n",
    "all_dna = all_dna.view('S4').reshape((all_dna.size, -1)).view(np.uint32)\n",
    "all_dna = torch.nn.functional.one_hot(torch.tensor(nucs[all_dna])).permute((0,2,1))\n",
    "all_dna = all_dna.to(device) * 1.0\n",
    "\n",
    "#Protein seq to tensor, with stop\n",
    "for i in range(len(all_prot)):\n",
    "    prot = np.array(all_prot[i])\n",
    "    prot = prot.view('S4').reshape((prot.size, -1)).view(np.uint32)\n",
    "    prot = F.one_hot(torch.tensor(aas[prot])).permute((0,2,1))\n",
    "    prot = prot.to(device) * 1.0\n",
    "    all_prot[i] = prot\n",
    "\n",
    "#Split train-test sets\n",
    "train_dna = all_dna[0:train_size]\n",
    "test_dna = all_dna[train_size:len(all_dna)]\n",
    "train_withstop = [ all_prot[i][0:train_size] for i in range(len(all_prot)) ]\n",
    "test_withstop = [ all_prot[i][train_size:len(all_prot[i])] for i in range(len(all_prot)) ]\n",
    "'''\n",
    "\n",
    "#torch.save([train_dna, test_dna, train_withstop, test_withstop], \"./translator_training_data.pth\")\n",
    "train_dna, test_dna, train_withstop, test_withstop = torch.load(\"./translator_training_data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f6314d-0cd1-41b0-b395-56767db65a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function for translation net\n",
    "sim_func = nn.CosineSimilarity(dim=1, eps=1e-16)\n",
    "def loss_func(pred, target):\n",
    "    loss = torch.tensor([0.0]).to(device)\n",
    "    for i in range(len(target)):\n",
    "        loss += (torch.mean(torch.sum(sim_func(pred[i], target[i]), dim=1)) * -1.0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3739e52d-8847-4241-8787-64e1c925e7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "  batch 200 loss: -4511.618125\n",
      "  batch 400 loss: -5716.733125\n",
      "  batch 600 loss: -5942.32625\n",
      "  batch 800 loss: -5992.0\n",
      "  batch 1000 loss: -5992.0\n",
      "  batch 1200 loss: -5992.0\n",
      "epoch 1\n",
      "  batch 200 loss: -5962.04\n",
      "  batch 400 loss: -5992.0\n",
      "  batch 600 loss: -5992.0\n",
      "  batch 800 loss: -5992.0\n",
      "  batch 1000 loss: -5992.0\n",
      "  batch 1200 loss: -5992.0\n"
     ]
    }
   ],
   "source": [
    "#512 channel CNN translator\n",
    "translator = Translator(512).to(device)\n",
    "\n",
    "#Training translation net\n",
    "batch_size = 8\n",
    "n_epoch = 2\n",
    "n_train = len(train_withstop[0])\n",
    "\n",
    "opt_params = [ i for i in translator.parameters() ]\n",
    "optimizer = torch.optim.SGD(opt_params, lr=1e-6, momentum=0.9)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    training_iter = 0\n",
    "    last_index = 0\n",
    "    print('epoch ' + str(epoch))\n",
    "    while last_index < n_train:\n",
    "        last_index_end = min(last_index + batch_size, n_train)\n",
    "        input_onehot = train_dna[last_index:last_index_end]\n",
    "        withstop = [ train_withstop[i][last_index:last_index_end, :, :] for i in range(len(train_withstop)) ]\n",
    "        stop = [ torch.hstack((train_withstop[i][last_index:last_index_end, 20:21, :], torch.abs(train_withstop[i][last_index:last_index_end, 20:21, :]-1))) for i in range(len(train_withstop)) ]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out_withstop, out_stop = translator(input_onehot, temperature=1.0)\n",
    "        loss_withstop = loss_func(out_withstop, withstop)\n",
    "        loss_stop = loss_func(out_stop, stop)\n",
    "        loss = loss_withstop + loss_stop\n",
    "        loss.backward()\n",
    "        losses += [loss.detach().clone()]\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        last_index = last_index_end \n",
    "        training_iter += 1        \n",
    "        \n",
    "        if training_iter % 200 == 199:\n",
    "            last_loss = running_loss / 200 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(training_iter + 1, last_loss))\n",
    "            running_loss = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "852f75af-4bea-4603-bace-0aad6ce08253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Check error rate on test set\n",
    "with torch.no_grad():\n",
    "    test_dna_sub = test_dna[0:100]\n",
    "    test_withstop_sub = [t[0:100] for t in test_withstop]\n",
    "    test_stop_sub = [t[0:100][:,20:21,:] for t in test_withstop]\n",
    "    pred_withstop, pred_stop = translator(test_dna_sub, temperature=1.0)\n",
    "    \n",
    "    error_withstop = torch.stack([ torch.mean(torch.sum(torch.argmax(pred_withstop[i], 1) != torch.argmax(test_withstop_sub[i], 1), dim=1)*1.0) / len_pro for i in range(len(pred_withstop)) ])\n",
    "    error_stop = torch.stack([ torch.mean(torch.sum(pred_stop[i][:,0:1,:] != test_stop_sub[i], dim=1)*1.0) / len_pro for i in range(len(pred_stop)) ])\n",
    "\n",
    "print(error_withstop)\n",
    "print(error_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47396dd9-dc7a-45c1-8708-6f72a9672be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(translator, \"./weights/translator/translator_cnn_512ch.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8280b04-cebf-4dd4-9104-07da6a2c44db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(test_dna_sub)[0][0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rofold_test2]",
   "language": "python",
   "name": "conda-env-rofold_test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
